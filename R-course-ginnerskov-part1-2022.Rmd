---
title: "Text analysis I: A conceptual background"
subtitle: "Introduction to R for Social Sciences"
author: 
- "Josef Ginnerskov, doctoral candidate"
# Uncomment the line below for adding more authors
#- "Another Author"
institute: "Department of Sociology"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    self_contained: true # This allows to use the html file without copying all files.
    lib_dir: libs
    css: ["./resources/css/uppsala.css", "./resources/css/uppsala-fonts.css"]
    includes:
      in_header: "./libs/partials/header.html"
#      after_body: "./resources/html/insert-logo.html"
    nature:
      beforeInit: ["./resources/js/macro.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      ratio: "16:9" # If you change it to 4:3, open insert-logo.html to fix the watermark position.
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,
                      message = F,
                      warning = F,
                      dpi = 600,
                      fig.asp = 0.5, # You may change these parameters for each chunk as needed.
                      fig.align="center",
                      out.width = "80%")

library(tidyverse)



#For exporting as pdf, run 'pagedown::chrome_print('html')' in the console, where 'html' is the name of html file to be exported as pdf (in this case, 'template.html').

```

# Computational text analysis?

--

1. New expression for quantitative text analysis (see also text mining)

--

2. Draws heavily on NLP (natural language processing), which is increasingly drawing on machine learning (a branch of AI)

--

3. Social scientists leveraging on tools generated in computer science, data science and linguistics (see also computational social science)

--

4. Most common tasks are data exploration and data classification (e.g. what topics are 2000 sociology abstracts writing about based on their most frequent words or are these 362 IMBD reviews of "Sex and the City 2" mostly negative or positive based on their sentiments)

# Call a spade a spade - or a shovel (1/3)
## Documents
--

1. Book, article, post, message ... = __document__

--

2. Document + document = __corpus__ (or data set)

--

3. Corpus + corpus = __corpora__ (or data sets)

---

# Call a spade a spade - or a shovel (2/3)
## Words
--

1. Combinations of letters = __words__ or __terms__ or __tokens__ or __features__ or __n-grams__

--

2. N-grams include __unigrams__ (e.g. horse), __bigrams__ (e.g. cultural capital) and __trigrams__ (e.g. social media trolls)

--

3. Common "set of words" types: __vocabulary__ (i.e. all words occurring in your corpus), __dictionary__ (e.g. a set of words of interest for your analysis), __stop words__ (insignificant words to exclude from the data), and __lexicons__ ([pre-made] word lists for categorizing your vocabulary needed for particular tasks)

---

# Call a spade a spade - or a shovel (3/3)
## Representations

--

1a. The __bag-of-words model__ or __one-hot vectors__ (words are stripped of their placement in sentences so that each document is reduced to a "bag" containing only word frequencies)

--

1b. The __document-term matrix__ aka __document-feature matrix__ (each row represents a document and each column a word) or the __tidy text tibble__ (each row has one column for the word and another for each document containing the word)

--

1c. __Term frequency-inverse document frequency__ (a weighted matrix that intends to show how important words are to a document in relation to the other documents in a corpus)

--

1d. __Topic modeling__ (an unsupervised machine learning technique to explore what topics are most relevant in a corpus; based on the idea that distinctly co-occurring words make up a  documents are)

--

2a. __Word embeddings__ (include statistics on each words' neighbors in the text, i.e. the words are embedded in the text)

--

2b. __Vector space__ (through word vectors we can generate a multi-dimensional representation of all words based on their co-occurrences)

---

# Turning text into data (1/2)
## Access

--

1. Data from traditional methods (open answers in questionnaires, interview scripts, field notes ...)

--

2. Digitize physical texts (scan &rarr; OCR &rarr; encode &rarr; load into R)

--

3. Download from digital archives ( __Gutenberg__, Runeberg, Scopus, Web of science ...)

--

4. Scraping websites (e.g. social media platforms like Twitter and Reddit)

---

# Turning text into data (2/2)
## Preprocess
--

Generate data set

--

1. Decide what documents make up your corpus and load the data

--

2. Add metadata (variables like author, publication year ...)

--

Tokenization

--

1. Remove what is not a word (remove: upper case, numbers, punctiation, white space...)

--

2. Decide what is a word (stemming, lemmatization, removing stop words )

--

3. Categorize words (Part-of-speech (POS) tagging, sentiment analysis...)

---

# Some text analysis task solvable with R

--

1. Global and local word occurrence counts (e.g. wordcloud)

--

2. Words specific for each text in relation to the corpus (e.g. tf-idf)

--

3. Relations between words (e.g. cluster analysis or co-occurrence network analysis)

--

4. Themes associated with each text (e.g. topic modeling)

--

5. Emotions in texts (sentiment analysis) 

--

6. The "meaning" of words (word embeddings)

--

7. The style of authors (stylometry)

---

# Some popular R packages for text analysis

--

- __tm__ (general text mining, corpus-based)

--

- __tidytext__ (R specific leveraging the tidy format)

--

- __quanteda__ (all-encompassing quantitative text analysis)

--

- __koRpus__ (preprocessing and general statistics for single texts)

--

- __udpipe__ and __opennlp__ (natural language processing toolkit)

--

- __text2vec__ (advance machine learning tasks like word embeddings)

--

- __stm__ (structural topic modeling), __lsa__ (latent semantic analysis) and __wordcloud__ (...wordclouds)

--

- __stylo__ (stylometric tasks like author attribution)

---

# Thank you for your time!

## Do not hesitate to contact me

|                                                                                              |                          |
|:---------------------------------------------------------------------------------------------|:-------------------------|
| <a href="mailto:josef.ginnerskov@soc.uu.se">.UUred[<i class="fa fa-paper-plane fa-fw"></i>] |josef.ginnerskov@soc.uu.se |  
| <a href="http://twitter.com/doeparen">.UUred[<i class="fa fa-twitter fa-fw"></i>]         |@doeparen              |
| <a href="http://github.com/doeparen">.UUred[<i class="fa fa-gitlab fa-fw"></i>]           |@doeparen              |
